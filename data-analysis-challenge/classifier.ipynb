{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "### The search sessions with a missing country either come from a country that is completely missing from the data, or from one of the countries that are logged in the data. Determine which country it is the most likely to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'city_search.json'\n",
    "df = pd.read_json(url, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cities</th>\n",
       "      <th>session_id</th>\n",
       "      <th>unix_timestam p</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[New York NY, Newark NJ]</td>\n",
       "      <td>[X061RFWB06K9V]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1442503708]</td>\n",
       "      <td>[[{'country': 'UK', 'joining_date': '2015-03-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[New York NY, Jersey City NJ, Philadelphia PA]</td>\n",
       "      <td>[5AZ2X2A9BHH5U]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1441353991]</td>\n",
       "      <td>[[{'country': 'DE', 'joining_date': '2015-03-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cities       session_id  \\\n",
       "0                        [New York NY, Newark NJ]  [X061RFWB06K9V]   \n",
       "1  [New York NY, Jersey City NJ, Philadelphia PA]  [5AZ2X2A9BHH5U]   \n",
       "\n",
       "  unix_timestam p unix_timestamp  \\\n",
       "0             NaN   [1442503708]   \n",
       "1             NaN   [1441353991]   \n",
       "\n",
       "                                                user  \n",
       "0  [[{'country': 'UK', 'joining_date': '2015-03-2...  \n",
       "1  [[{'country': 'DE', 'joining_date': '2015-03-2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge defective timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cities</th>\n",
       "      <th>session_id</th>\n",
       "      <th>unix_timestam p</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[New York NY, Newark NJ]</td>\n",
       "      <td>[X061RFWB06K9V]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1442503708]</td>\n",
       "      <td>[[{'country': 'UK', 'joining_date': '2015-03-2...</td>\n",
       "      <td>[1442503708]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[New York NY, Jersey City NJ, Philadelphia PA]</td>\n",
       "      <td>[5AZ2X2A9BHH5U]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1441353991]</td>\n",
       "      <td>[[{'country': 'DE', 'joining_date': '2015-03-2...</td>\n",
       "      <td>[1441353991]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cities       session_id  \\\n",
       "0                        [New York NY, Newark NJ]  [X061RFWB06K9V]   \n",
       "1  [New York NY, Jersey City NJ, Philadelphia PA]  [5AZ2X2A9BHH5U]   \n",
       "\n",
       "  unix_timestam p unix_timestamp  \\\n",
       "0             NaN   [1442503708]   \n",
       "1             NaN   [1441353991]   \n",
       "\n",
       "                                                user     timestamp  \n",
       "0  [[{'country': 'UK', 'joining_date': '2015-03-2...  [1442503708]  \n",
       "1  [[{'country': 'DE', 'joining_date': '2015-03-2...  [1441353991]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'] = df['unix_timestam p'].combine_first(df['unix_timestamp'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colNames = ['cities', 'user']\n",
    "def extract_country(user):\n",
    "    return  user[0][0]['country']\n",
    "\n",
    "flattened_data_frame = pd.DataFrame(columns = ['country', 'cities', 'user'])\n",
    "flattened_data_frame['cities'] = df['cities'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "flattened_data_frame['timestamp'] = df['timestamp'].apply(lambda x:  x[0])\n",
    "flattened_data_frame['session_id'] = df.apply(lambda x: x['session_id'][0], axis=1)\n",
    "flattened_data_frame['user'] = df['user'].apply(lambda x:  x[0][0]['user_id'])\n",
    "flattened_data_frame['country'] = df.apply(lambda x: extract_country(x[colNames[1]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>cities</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>New York NY, Newark NJ</td>\n",
       "      <td>2024</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>New York NY, Jersey City NJ, Philadelphia PA</td>\n",
       "      <td>2853</td>\n",
       "      <td>1441353991</td>\n",
       "      <td>5AZ2X2A9BHH5U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>San Antonio TX</td>\n",
       "      <td>10958</td>\n",
       "      <td>1440843490</td>\n",
       "      <td>SHTB4IYAX4PX6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        cities   user   timestamp  \\\n",
       "0      UK                        New York NY, Newark NJ   2024  1442503708   \n",
       "1      DE  New York NY, Jersey City NJ, Philadelphia PA   2853  1441353991   \n",
       "2      UK                                San Antonio TX  10958  1440843490   \n",
       "\n",
       "      session_id  \n",
       "0  X061RFWB06K9V  \n",
       "1  5AZ2X2A9BHH5U  \n",
       "2  SHTB4IYAX4PX6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattened_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Pandas Dataframe 'Cities' column containing lists into multiple rows, duplicating the other column's values.\n",
    "\n",
    "#Following function is taken from: https://gist.github.com/jlln/338b4b0b55bd6984f883 [[[\n",
    "def splitDataFrameList(df,target_column,separator):\n",
    "    ''' df = dataframe to split,\n",
    "    target_column = the column containing the values to split\n",
    "    separator = the symbol used to perform the split\n",
    "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "    The values in the other columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s.lstrip()\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n",
    "# ]]]\n",
    "\n",
    "cities = splitDataFrameList(flattened_data_frame, 'cities', ',')\n",
    "# rename the column\n",
    "cities.rename(columns={'cities':'city'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York NY</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newark NJ</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York NY</td>\n",
       "      <td>DE</td>\n",
       "      <td>5AZ2X2A9BHH5U</td>\n",
       "      <td>1441353991</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city country     session_id   timestamp  user\n",
       "0  New York NY      UK  X061RFWB06K9V  1442503708  2024\n",
       "1    Newark NJ      UK  X061RFWB06K9V  1442503708  2024\n",
       "2  New York NY      DE  5AZ2X2A9BHH5U  1441353991  2853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('city_frequency', (cities['city'], cities['city'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert city column to a category, then use those category values for label encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities['city'] = cities['city'].astype('category')\n",
    "cities[\"city\"] = cities[\"city\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>DE</td>\n",
       "      <td>5AZ2X2A9BHH5U</td>\n",
       "      <td>1441353991</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city country     session_id   timestamp  user\n",
       "0    50      UK  X061RFWB06K9V  1442503708  2024\n",
       "1    51      UK  X061RFWB06K9V  1442503708  2024\n",
       "2    50      DE  5AZ2X2A9BHH5U  1441353991  2853"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33016"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_train = cities[cities['country'] != '']\n",
    "data_to_predict = cities[cities['country'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4619"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a country classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_to_train[['city', 'user']]\n",
    "y = data_to_train['country']\n",
    "X_predict = data_to_predict.loc[:, ['city','user']]\n",
    "\n",
    "np.save('X', X)\n",
    "np.save('y', y)\n",
    "np.save('X_predict', X_predict)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_predict = StandardScaler().fit_transform(X_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit Support Vector Machine Classifier\n",
    "# from the docstring:\n",
    "'''C-Support Vector Classification.\n",
    "\n",
    "The implementation is based on libsvm. The fit time complexity\n",
    "is more than quadratic with the number of samples which makes it hard\n",
    "to scale to dataset with more than a couple of 10000 samples.\n",
    "\n",
    "The multiclass support is handled according to a one-vs-one scheme.\n",
    ".\n",
    ".\n",
    ".\n",
    "decision_function_shape : 'ovo', 'ovr'\n",
    "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
    "    (n_samples, n_classes) as all other classifiers, or the original\n",
    "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
    "    (n_samples, n_classes * (n_classes - 1) / 2).\n",
    "'''\n",
    "clf = svm.SVC(decision_function_shape='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect clasiffier classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DE', 'ES', 'FR', 'IT', 'UK', 'US'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test dataset: 0.233098591549\n"
     ]
    }
   ],
   "source": [
    " print (\"Accuracy for test dataset: %s\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the whole datase (except the records with defective country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DE' 1061]\n",
      " ['UK' 782]\n",
      " ['US' 2776]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(Y_predict, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this classifier, from all predictions(4619), 60% of predictions(2776) are 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_svc.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'classifier_svc.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach: KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit KNeighborsClassifier\n",
    "# from the docstring:\n",
    "'''Classifier implementing the k-nearest neighbors vote.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n_neighbors : int, optional (default = 5)\n",
    "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "    \n",
    "Regarding the Nearest Neighbors algorithms, if it is found that two\n",
    "neighbors, neighbor `k+1` and `k`, have identical distances\n",
    "but different labels, the results will depend on the ordering of the\n",
    "training data.    \n",
    "'''\n",
    "clf_kn = KNeighborsClassifier(7)\n",
    "\n",
    "\n",
    "\n",
    "# flattened_data_frame['cities'] = flattened_data_frame['cities'].astype('category')\n",
    "# flattened_data_frame['session_id'] = flattened_data_frame['session_id'].astype('category')\n",
    "# flattened_data_frame['timestamp'] = flattened_data_frame['timestamp'].astype('category')\n",
    "# flattened_data_frame[\"cities\"] = flattened_data_frame[\"cities\"].cat.codes\n",
    "# flattened_data_frame[\"session_id\"] = flattened_data_frame[\"session_id\"].cat.codes\n",
    "# flattened_data_frame[\"timestamp\"] = flattened_data_frame[\"timestamp\"].cat.codes\n",
    "\n",
    "\n",
    "# data_to_train = flattened_data_frame[flattened_data_frame['country'] != '']\n",
    "# data_to_predict = flattened_data_frame[flattened_data_frame['country'] == '']\n",
    "# X = data_to_train[['cities', 'user', 'timestamp', 'session_id']]\n",
    "# y = data_to_train['country']\n",
    "\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>UK</td>\n",
       "      <td>X061RFWB06K9V</td>\n",
       "      <td>1442503708</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city country     session_id   timestamp  user\n",
       "0    50      UK  X061RFWB06K9V  1442503708  2024\n",
       "1    51      UK  X061RFWB06K9V  1442503708  2024"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_kn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect clasiffier classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DE', 'ES', 'FR', 'IT', 'UK', 'US'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_kn.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2272887323943662"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = clf_kn.score(X_test, y_test)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DE' 1061]\n",
      " ['UK' 782]\n",
      " ['US' 2776]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(Y_predict, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this classifier, from all predictions(4619), 72% of predictions(3356) are 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_knn.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_kn, 'classifier_knn.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach: OneVsRestClassifier from sklearn.multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit OneVsRestClassifier Classifier\n",
    "# from the docstring:\n",
    "'''One-vs-the-rest (OvR) multiclass/multilabel strategy\n",
    "\n",
    "Also known as one-vs-all, this strategy consists in fitting one classifier\n",
    "per class. For each classifier, the class is fitted against all the other\n",
    "classes. In addition to its computational efficiency (only `n_classes`\n",
    "classifiers are needed), one advantage of this approach is its\n",
    "interpretability. Since each class is represented by one and one classifier\n",
    "only, it is possible to gain knowledge about the class by inspecting its\n",
    "corresponding classifier. This is the most commonly used strategy for\n",
    "multiclass classification and is a fair default choice.\n",
    "\n",
    "This strategy can also be used for multilabel learning, where a classifier\n",
    "is used to predict multiple labels for instance, by fitting on a 2-d matrix\n",
    "in which cell [i, j] is 1 if sample i has label j and 0 otherwise.\n",
    "\n",
    "In the multilabel learning literature, OvR is also known as the binary\n",
    "relevance method.\n",
    "'''\n",
    "clf = OneVsRestClassifier(svm.SVC(decision_function_shape='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect clasiffier classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DE', 'ES', 'FR', 'IT', 'UK', 'US'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the whole datase (except the records with defective country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DE' '886']\n",
      " ['ES' '896']\n",
      " ['FR' '101']\n",
      " ['IT' '626']\n",
      " ['UK' '980']\n",
      " ['US' '1130']]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(Y_predict, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_ovr_multi.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'classifier_ovr_multi.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
